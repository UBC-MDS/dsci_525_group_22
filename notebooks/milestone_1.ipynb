{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "import zipfile\n",
    "import glob\n",
    "import re\n",
    "import pyarrow as pa\n",
    "import rpy2_arrow.pyarrow_rarrow as pyra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata\n",
    "article_id = 14096681\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "out_dir = os.path.join(\"../data\", \"raw\", \"figshare\")\n",
    "file_to_download = \"data.zip\"\n",
    "\n",
    "# Get file url\n",
    "file_url = [\n",
    "    item_[\"download_url\"]\n",
    "    for item_ in requests.get(url, headers=headers).json()[\"files\"]\n",
    "    if item_[\"name\"] == file_to_download\n",
    "][0]\n",
    "\n",
    "# Check if file has already been downloaded\n",
    "if os.listdir(out_dir):\n",
    "    print(\"File already exists. Skipping.\")\n",
    "else:\n",
    "    print(f\"Writing file file {file_to_download} to directory {out_dir}\")\n",
    "\n",
    "    # Create an HTTP request\n",
    "    with requests.get(file_url, stream=True) as r:\n",
    "\n",
    "        # Check content length\n",
    "        content_length = int(r.headers.get(\"Content-Length\"))\n",
    "\n",
    "        # SDisplay progress bar\n",
    "        with tqdm.wrapattr(r.raw, \"read\", total=content_length, desc=\"\") as raw:\n",
    "\n",
    "            # Save file\n",
    "            with open(os.path.join(out_dir, file_to_download), \"wb\") as path:\n",
    "                shutil.copyfileobj(raw, path)\n",
    "\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "    # Unzip file with python\n",
    "    print(\"Unzipping file...\")\n",
    "    with zipfile.ZipFile(os.path.join(out_dir, file_to_download), \"r\") as zip_ref:\n",
    "        zip_ref.extractall(out_dir) # Extract all files to directory\n",
    "    print(\"Unzipping complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Combining data csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_processed_dir = os.path.join(\"../data\", \"processed\", \"figshare\")\n",
    "file_to_exclude = \"observed_daily_rainfall_SYD.csv\"\n",
    "files = glob.glob(out_dir + \"/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1\n",
    "\n",
    "# Combine data\n",
    "df = pd.concat(\n",
    "    (\n",
    "        pd.read_csv(file, index_col=0).assign(model=re.findall(r\"[A-Z][^_]+\", file)[0])\n",
    "        for file in files\n",
    "        if file != file_to_exclude\n",
    "    )\n",
    ")\n",
    "\n",
    "# Write to file\n",
    "os.makedirs(out_processed_dir, exist_ok=True)  \n",
    "df.to_csv(os.path.join(out_processed_dir, \"processed_rainfall.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare run times on different machines\n",
    "\n",
    "| Team Member        | Operating System | RAM  | Processor              | Is SSD | Time taken |\n",
    "|:------------------:|:----------------:|:----:|:----------------------:|:------:|:----------:|\n",
    "| Rakesh Pandey      | Ubuntu 20.04     | 32GB | Intel® Core™ i7-10870H | Yes    | 4min 50s   |\n",
    "| Mahsa Sarafrazi    |                  |      |                        |        |            |\n",
    "| Gabe Fairbrother   |                  |      |                        |        |            |\n",
    "| Michelle Wang      |                  |      |                        |        |            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load the combined CSV to memory and perform a simple EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Load all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(os.path.join(out_processed_dir, \"processed_rainfall.csv\"), index_col=0)\n",
    "\n",
    "# Get the model counts\n",
    "print(\"Model counts:\")\n",
    "print(df.model.value_counts())\n",
    "\n",
    "# Describe the data\n",
    "print(\"Data description:\")  \n",
    "print(df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare run times on different machines\n",
    "\n",
    "| Team Member        | Operating System | RAM  | Processor              | Is SSD | Time taken |\n",
    "|:------------------:|:----------------:|:----:|:----------------------:|:------:|:----------:|\n",
    "| Rakesh Pandey      | Ubuntu 20.04     | 32GB | Intel® Core™ i7-10870H | Yes    | 6min 39s   |\n",
    "| Mahsa Sarafrazi    |                  |      |                        |        |            |\n",
    "| Gabe Fairbrother   |                  |      |                        |        |            |\n",
    "| Michelle Wang      |                  |      |                        |        |            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Load only required columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1\n",
    "use_cols = [\"time\", \"rain (mm/day)\", \"model\"]\n",
    "df = pd.read_csv(\n",
    "    os.path.join(out_processed_dir, \"processed_rainfall.csv\"),\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    "    usecols=use_cols,\n",
    ")\n",
    "\n",
    "# Get the model counts\n",
    "print(\"Model counts:\")\n",
    "print(df.model.value_counts())\n",
    "\n",
    "# Describe the data\n",
    "print(\"Data description:\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare run times on different machines\n",
    "\n",
    "| Team Member        | Operating System | RAM  | Processor              | Is SSD | Time taken |\n",
    "|:------------------:|:----------------:|:----:|:----------------------:|:------:|:----------:|\n",
    "| Rakesh Pandey      | Ubuntu 20.04     | 32GB | Intel® Core™ i7-10870H | Yes    | 6min 39s   |\n",
    "| Mahsa Sarafrazi    |                  |      |                        |        |            |\n",
    "| Gabe Fairbrother   |                  |      |                        |        |            |\n",
    "| Michelle Wang      |                  |      |                        |        |            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Change dtype and use only required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1\n",
    "\n",
    "use_cols = [\"time\", \"rain (mm/day)\", \"model\"]\n",
    "dtypes = {\"rain (mm/day)\": \"float32\", \"model\": \"str\"}\n",
    "\n",
    "df = pd.read_csv(\n",
    "    os.path.join(out_processed_dir, \"processed_rainfall.csv\"),\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    "    usecols=use_cols,\n",
    "    dtype=dtypes,\n",
    ")\n",
    "\n",
    "# Get the model counts\n",
    "print(\"Model counts:\")\n",
    "print(df.model.value_counts())\n",
    "\n",
    "# Describe the data\n",
    "print(\"Data description:\")\n",
    "print(df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare run times on different machines\n",
    "\n",
    "| Team Member        | Operating System | RAM  | Processor              | Is SSD | Time taken |\n",
    "|:------------------:|:----------------:|:----:|:----------------------:|:------:|:----------:|\n",
    "| Rakesh Pandey      | Ubuntu 20.04     | 32GB | Intel® Core™ i7-10870H | Yes    | 6min 39s   |\n",
    "| Mahsa Sarafrazi    |                  |      |                        |        |            |\n",
    "| Gabe Fairbrother   |                  |      |                        |        |            |\n",
    "| Michelle Wang      |                  |      |                        |        |            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Use chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for chunk in pd.read_csv(\n",
    "    os.path.join(out_processed_dir, \"processed_rainfall.csv\"),\n",
    "    index_col=0,\n",
    "    parse_dates=True, \n",
    "    chunksize=1_000_000):\n",
    "    df = df.append(chunk)\n",
    "\n",
    "# Get the model counts\n",
    "print(\"Model counts:\")\n",
    "print(df.model.value_counts())\n",
    "\n",
    "# Describe the data\n",
    "print(\"Data description:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare run times on different machines\n",
    "\n",
    "| Team Member        | Operating System | RAM  | Processor              | Is SSD | Time taken |\n",
    "|:------------------:|:----------------:|:----:|:----------------------:|:------:|:----------:|\n",
    "| Rakesh Pandey      | Ubuntu 20.04     | 32GB | Intel® Core™ i7-10870H | Yes    | 6min 39s   |\n",
    "| Mahsa Sarafrazi    |                  |      |                        |        |            |\n",
    "| Gabe Fairbrother   |                  |      |                        |        |            |\n",
    "| Michelle Wang      |                  |      |                        |        |            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Perform a simple EDA in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach to transfer data from python to R**\n",
    "\n",
    "We are more inclined to use the 'Arrow Exchange' method. Using 'Apache Arrow' as an intermediate step can speed up the conversion of a 'pandas. DataFrame'. The pyarrow package uses compiled code to efficiently convert a 'pandas. DataFrame' to a 'Arrow' data structure, and the R package arrow can do the same from a 'Arrow' data structure to a 'R data.frame'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time spent on this serialization/deserialization process is very less and is also a zero-copy process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rdf = pyra.converter.py2rpy(pa.Table.from_pandas(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R -i rdf\n",
    "library(dplyr)\n",
    "\n",
    "# Get the model counts\n",
    "print(\"Model counts:\")\n",
    "print(count(rdf, model, sort = TRUE))\n",
    "\n",
    "# Describe the data\n",
    "print(\"Data description:\")\n",
    "print(summary(rdf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0431e97599bb9ae06b62e9e4cc0acb5e2f4237c339c3eea49a31a7ce8607a15c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('525')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
